# @package _global_
# RL Custom Reward Experiment Configuration
#
# This example demonstrates two ways to specify checkpoint paths:
#   1. Direct file path: "ckpts/alex_mp_20/ldm/ldm_null_k744ob4i.ckpt"
#   2. Hub resolver (downloads from HuggingFace): "${hub:alex_mp_20_ldm}"
#
# Available checkpoint names (see checkpoints/checkpoints.yaml):
#   - mp_20_vae, alex_mp_20_vae
#   - mp_20_ldm, alex_mp_20_ldm

defaults:
  - override /data: alex_mp_20
  - override /rl_module: rl_module
  - override /callbacks: default
  - override /logger: wandb
  - override /scheduler: constant
  - override /paths: default
  - override /hydra: default

data:
  batch_size: 5

rl_module:
  # Use hub: resolver to automatically download checkpoints from HuggingFace
  ldm_ckpt_path: ${hub:alex_mp_20_ldm}
  vae_ckpt_path: ${hub:alex_mp_20_vae}

  # Alternative: Use direct file paths (if checkpoints are already downloaded)
  # ldm_ckpt_path: ckpts/alex_mp_20/ldm/ldm_null_k744ob4i.ckpt
  # vae_ckpt_path: ckpts/alex_mp_20/vae/dng_j1jgz9t0_v1.ckpt

  rl_configs:
    num_group_samples: 64
    group_reward_norm: true

  reward_fn:
    _target_: src.rl_module.reward.ReinforceReward
    normalize_fn: std
    eps: 1e-4
    reference_dataset: mp-20
    components:
      - _target_: src.rl_module.components.CreativityReward
        weight: 1.0
        normalize_fn: null
      - _target_: src.rl_module.components.EnergyReward
        weight: 1.0
        normalize_fn: norm
      - _target_: src.rl_module.components.StructureDiversityReward
        weight: 0.1
        normalize_fn: norm
      - _target_: src.rl_module.components.CompositionDiversityReward
        weight: 1.0
        normalize_fn: norm

logger:
  wandb:
    name: rl_dng
