# Checkpoint Management Plan

**Issue**: CI failing due to missing model checkpoints (VAE, LDM) required by baseline tests
**Solution**: Hugging Face Hub-based checkpoint download/caching system

## Checkpoints to Manage

```
ckpts/mp_20/vae/dng_m4owq4i5_v0.ckpt           # VAE for MP-20 dataset
ckpts/alex_mp_20/vae/dng_j1jgz9t0_v1.ckpt      # VAE for Alex MP-20 dataset
ckpts/mp_20/ldm/ldm_rl_dng_xxq3a0mn.ckpt       # LDM for MP-20 dataset
ckpts/alex_mp_20/ldm/ldm_rl_dng_tuor5vgd.ckpt  # LDM for Alex MP-20 dataset
```

---

## Tasks (T033-T039)

### T033: Create Checkpoint Configuration

**File**: `checkpoints/checkpoints.yaml`

```yaml
checkpoints:
  mp_20_vae:
    filename: dng_m4owq4i5_v0.ckpt
    hf_path: mp_20/vae/dng_m4owq4i5_v0.ckpt
    sha256: <to_be_calculated>
    description: "VAE model for MP-20 dataset"

  alex_mp_20_vae:
    filename: dng_j1jgz9t0_v1.ckpt
    hf_path: alex_mp_20/vae/dng_j1jgz9t0_v1.ckpt
    sha256: <to_be_calculated>
    description: "VAE model for Alex MP-20 dataset"

  mp_20_ldm:
    filename: ldm_rl_dng_xxq3a0mn.ckpt
    hf_path: mp_20/ldm/ldm_rl_dng_xxq3a0mn.ckpt
    sha256: <to_be_calculated>
    description: "LDM model for MP-20 dataset"

  alex_mp_20_ldm:
    filename: ldm_rl_dng_tuor5vgd.ckpt
    hf_path: alex_mp_20/ldm/ldm_rl_dng_tuor5vgd.ckpt
    sha256: <to_be_calculated>
    description: "LDM model for Alex MP-20 dataset"

config:
  hf_repo: "your-org/chemeleon2-checkpoints"
  cache_dir: "./checkpoints"
```

---

### T034: Checkpoint Downloader Utility

**File**: `src/utils/checkpoint_downloader.py`

```python
"""Checkpoint download and caching utility using Hugging Face Hub."""

import hashlib
import os
from pathlib import Path
from typing import Optional

import yaml
from huggingface_hub import hf_hub_download
from huggingface_hub.utils import HfHubHTTPError

CHECKPOINT_CONFIG = Path(__file__).parent.parent.parent / "checkpoints" / "checkpoints.yaml"


class CheckpointSkipped(Exception):
    """Raised when checkpoint download is skipped (e.g., in CI)."""
    pass


def load_checkpoint_config() -> dict:
    """Load checkpoint configuration from YAML file."""
    with open(CHECKPOINT_CONFIG) as f:
        return yaml.safe_load(f)


def calculate_sha256(file_path: Path) -> str:
    """Calculate SHA256 checksum of a file."""
    sha256_hash = hashlib.sha256()
    with open(file_path, "rb") as f:
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()


def verify_checksum(file_path: Path, expected_sha256: str) -> bool:
    """Verify file checksum matches expected value."""
    actual_sha256 = calculate_sha256(file_path)
    if actual_sha256 != expected_sha256:
        raise ValueError(
            f"Checksum mismatch for {file_path}!\n"
            f"Expected: {expected_sha256}\n"
            f"Got: {actual_sha256}"
        )
    return True


def get_checkpoint(name: str, force_download: bool = False) -> Path:
    """
    Download checkpoint from Hugging Face Hub if not cached.

    Args:
        name: Checkpoint name from config (e.g., 'mp_20_vae')
        force_download: Force re-download even if cached

    Returns:
        Path to downloaded/cached checkpoint

    Raises:
        CheckpointSkipped: If SKIP_CHECKPOINT_DOWNLOAD=true
        ValueError: If checksum verification fails
        KeyError: If checkpoint name not found in config
    """
    # Check if checkpoint downloads are disabled (e.g., in CI)
    if os.getenv("SKIP_CHECKPOINT_DOWNLOAD", "").lower() == "true":
        raise CheckpointSkipped(
            f"Checkpoint download skipped (SKIP_CHECKPOINT_DOWNLOAD=true). "
            f"Cannot load checkpoint: {name}"
        )

    # Load config
    config = load_checkpoint_config()
    if name not in config["checkpoints"]:
        raise KeyError(f"Checkpoint '{name}' not found in config")

    ckpt_info = config["checkpoints"][name]
    hf_repo = config["config"]["hf_repo"]
    cache_dir = Path(config["config"]["cache_dir"])

    # Download from Hugging Face Hub
    try:
        downloaded_path = hf_hub_download(
            repo_id=hf_repo,
            filename=ckpt_info["hf_path"],
            cache_dir=str(cache_dir),
            force_download=force_download,
        )
        downloaded_path = Path(downloaded_path)

        # Verify checksum if provided
        if ckpt_info.get("sha256") and ckpt_info["sha256"] != "<to_be_calculated>":
            verify_checksum(downloaded_path, ckpt_info["sha256"])

        print(f"âœ“ Checkpoint '{name}' ready at: {downloaded_path}")
        return downloaded_path

    except HfHubHTTPError as e:
        raise RuntimeError(
            f"Failed to download checkpoint '{name}' from Hugging Face Hub. "
            f"Make sure the repository '{hf_repo}' exists and is public. "
            f"Error: {e}"
        )
```

---

### T035: Checkpoint Downloader Tests

**File**: `tests/unit/test_checkpoint_downloader.py`

```python
"""Tests for checkpoint downloader utility."""

import os
from pathlib import Path
from unittest.mock import MagicMock, patch

import pytest

from src.utils.checkpoint_downloader import (
    CheckpointSkipped,
    calculate_sha256,
    get_checkpoint,
    verify_checksum,
)


@pytest.fixture
def mock_config():
    return {
        "checkpoints": {
            "test_ckpt": {
                "filename": "test.ckpt",
                "hf_path": "test/test.ckpt",
                "sha256": "abc123",
                "description": "Test checkpoint",
            }
        },
        "config": {
            "hf_repo": "test-org/test-repo",
            "cache_dir": "./checkpoints",
        },
    }


def test_skip_checkpoint_download_env_var(monkeypatch, mock_config):
    """Test that SKIP_CHECKPOINT_DOWNLOAD=true raises CheckpointSkipped."""
    monkeypatch.setenv("SKIP_CHECKPOINT_DOWNLOAD", "true")

    with patch("src.utils.checkpoint_downloader.load_checkpoint_config", return_value=mock_config):
        with pytest.raises(CheckpointSkipped, match="Checkpoint download skipped"):
            get_checkpoint("test_ckpt")


def test_checkpoint_not_found(mock_config):
    """Test that invalid checkpoint name raises KeyError."""
    with patch("src.utils.checkpoint_downloader.load_checkpoint_config", return_value=mock_config):
        with pytest.raises(KeyError, match="not found in config"):
            get_checkpoint("invalid_ckpt")


@patch("src.utils.checkpoint_downloader.hf_hub_download")
@patch("src.utils.checkpoint_downloader.verify_checksum")
def test_successful_download(mock_verify, mock_download, mock_config, monkeypatch):
    """Test successful checkpoint download."""
    monkeypatch.delenv("SKIP_CHECKPOINT_DOWNLOAD", raising=False)
    mock_download.return_value = "/cache/test.ckpt"
    mock_verify.return_value = True

    with patch("src.utils.checkpoint_downloader.load_checkpoint_config", return_value=mock_config):
        result = get_checkpoint("test_ckpt")

        assert result == Path("/cache/test.ckpt")
        mock_download.assert_called_once_with(
            repo_id="test-org/test-repo",
            filename="test/test.ckpt",
            cache_dir="./checkpoints",
            force_download=False,
        )


def test_checksum_verification(tmp_path):
    """Test checksum verification."""
    test_file = tmp_path / "test.txt"
    test_file.write_text("hello world")

    # Calculate actual checksum
    actual_checksum = calculate_sha256(test_file)

    # Valid checksum should pass
    assert verify_checksum(test_file, actual_checksum) is True

    # Invalid checksum should raise ValueError
    with pytest.raises(ValueError, match="Checksum mismatch"):
        verify_checksum(test_file, "invalid_checksum")
```

---

### T036: Update Baseline Tests

**Changes needed:**

1. **Add pytest marker to `pyproject.toml`:**
```toml
[tool.pytest.ini_options]
markers = [
    "smoke: Smoke tests for quick validation",
    "baseline: Baseline tests to prevent regressions",
    "unit: Unit tests",
    "integration: Integration tests",
    "slow: Slow-running tests",
    "requires_checkpoints: Tests requiring downloaded model checkpoints",
]
```

2. **Update `tests/conftest.py`:**
```python
import os
import pytest
from src.utils.checkpoint_downloader import CheckpointSkipped

def pytest_collection_modifyitems(config, items):
    """Auto-skip checkpoint tests if checkpoints unavailable."""
    skip_marker = pytest.mark.skip(reason="Checkpoints not available (SKIP_CHECKPOINT_DOWNLOAD=true)")

    for item in items:
        if "requires_checkpoints" in item.keywords:
            if os.getenv("SKIP_CHECKPOINT_DOWNLOAD", "").lower() == "true":
                item.add_marker(skip_marker)
```

3. **Update baseline test files:**
```python
# tests/baseline/test_vae_module.py
import pytest
from src.utils.checkpoint_downloader import get_checkpoint

@pytest.mark.smoke
@pytest.mark.baseline
@pytest.mark.requires_checkpoints
def test_vae_forward_pass():
    vae_ckpt_path = get_checkpoint("mp_20_vae")
    # ... rest of test
```

---

### T037: Update CI Workflow

**File**: `.github/workflows/ci.yml`

```yaml
name: CI

on:
  pull_request:
    branches:
      - main
      - develop
  push:
    branches:
      - main

jobs:
  lint-and-test:
    runs-on: ubuntu-latest

    env:
      SKIP_CHECKPOINT_DOWNLOAD: "true"  # Skip checkpoint tests in default CI run

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Ruff format check
        run: ruff format --check .

      - name: Ruff lint check
        run: ruff check .

      - name: Pyright type check
        run: pyright
        continue-on-error: true

      - name: Run tests (excluding checkpoint tests)
        run: pytest -m "not requires_checkpoints"

  # Optional: Manual trigger for checkpoint tests
  checkpoint-tests:
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch'  # Manual trigger only

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Run checkpoint tests
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}  # Optional: for private repos
        run: pytest -m requires_checkpoints
```

---

### T038: Checkpoint Upload Script

**File**: `scripts/upload_checkpoints.sh`

```bash
#!/bin/bash
set -e

# Upload checkpoints to Hugging Face Hub
# Usage: ./scripts/upload_checkpoints.sh
# Requires: huggingface-cli login (or HF_TOKEN env var)

HF_REPO="your-org/chemeleon2-checkpoints"

echo "ðŸš€ Uploading checkpoints to Hugging Face Hub: $HF_REPO"

# Check if huggingface-cli is installed
if ! command -v huggingface-cli &> /dev/null; then
    echo "âŒ Error: huggingface-cli not found. Install with: pip install huggingface_hub[cli]"
    exit 1
fi

# Check authentication
if [ -z "$HF_TOKEN" ] && ! huggingface-cli whoami &> /dev/null; then
    echo "âŒ Error: Not authenticated. Run 'huggingface-cli login' or set HF_TOKEN env var"
    exit 1
fi

# Upload 4 checkpoints
echo "ðŸ“¦ Uploading MP-20 VAE..."
huggingface-cli upload "$HF_REPO" \
    ckpts/mp_20/vae/dng_m4owq4i5_v0.ckpt \
    mp_20/vae/dng_m4owq4i5_v0.ckpt

echo "ðŸ“¦ Uploading Alex MP-20 VAE..."
huggingface-cli upload "$HF_REPO" \
    ckpts/alex_mp_20/vae/dng_j1jgz9t0_v1.ckpt \
    alex_mp_20/vae/dng_j1jgz9t0_v1.ckpt

echo "ðŸ“¦ Uploading MP-20 LDM..."
huggingface-cli upload "$HF_REPO" \
    ckpts/mp_20/ldm/ldm_rl_dng_xxq3a0mn.ckpt \
    mp_20/ldm/ldm_rl_dng_xxq3a0mn.ckpt

echo "ðŸ“¦ Uploading Alex MP-20 LDM..."
huggingface-cli upload "$HF_REPO" \
    ckpts/alex_mp_20/ldm/ldm_rl_dng_tuor5vgd.ckpt \
    alex_mp_20/ldm/ldm_rl_dng_tuor5vgd.ckpt

echo "âœ… All checkpoints uploaded successfully!"
echo "ðŸ“ Next step: Update checkpoints/checkpoints.yaml with SHA256 checksums"
```

---

### T039: Documentation

**Add to CONTRIBUTING.md:**

```markdown
## Working with Model Checkpoints

### Overview
Model checkpoints (VAE, LDM) are stored on Hugging Face Hub and downloaded automatically when running tests locally.

### Local Development

**First-time setup:**
```bash
# Install huggingface_hub
pip install huggingface_hub

# Run tests - checkpoints download automatically
pytest tests/baseline/
```

**Checkpoints are cached in `./checkpoints/` directory** - subsequent test runs use cached files.

**To force re-download:**
```python
from src.utils.checkpoint_downloader import get_checkpoint
checkpoint = get_checkpoint("mp_20_vae", force_download=True)
```

### CI/CD Behavior

Checkpoint tests are **skipped by default in CI** to speed up builds:
- Environment variable `SKIP_CHECKPOINT_DOWNLOAD=true` is set
- Tests marked with `@pytest.mark.requires_checkpoints` are skipped
- Run manually via workflow_dispatch if needed

### Uploading New Checkpoints

```bash
# 1. Authenticate with Hugging Face
huggingface-cli login

# 2. Upload checkpoints
./scripts/upload_checkpoints.sh

# 3. Calculate checksums
sha256sum ckpts/**/*.ckpt

# 4. Update checkpoints/checkpoints.yaml with new SHA256 values
```

### Available Checkpoints
- `mp_20_vae` - VAE for MP-20 dataset
- `alex_mp_20_vae` - VAE for Alex MP-20 dataset
- `mp_20_ldm` - LDM for MP-20 dataset
- `alex_mp_20_ldm` - LDM for Alex MP-20 dataset
```

---

## Execution Order

1. **T033** â†’ Create config file
2. **T034** â†’ Implement downloader
3. **T035** â†’ Test downloader (parallel with T034)
4. **T036** â†’ Update baseline tests
5. **T037** â†’ Update CI
6. **T038** â†’ Create upload script (parallel with T037)
7. **T039** â†’ Documentation

---

## Dependencies to Add

```toml
# pyproject.toml
[project]
dependencies = [
    # ... existing deps
    "huggingface_hub>=0.20.0",
    "pyyaml>=6.0",
]
```
